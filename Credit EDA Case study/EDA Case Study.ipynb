{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue> EDA Case Study </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Introduction </font>\n",
    "\n",
    "This case study aims to give an idea of applying EDA in a real business scenario. In this case study, we will develop a basic understanding of risk analytics in banking and financial services and understand how data is used to minimise the risk of losing money while lending to customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = blue> Business Understanding </font>\n",
    "\n",
    "This case study aims to identify patterns which indicate if a client has difficulty paying their installments which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc. This will ensure that the consumers capable of repaying the loan are not rejected. Identification of such applicants using EDA is the aim of this case study.\n",
    "\n",
    " \n",
    "\n",
    "In other words, the company wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default.  The company can utilise this knowledge for its portfolio and risk assessment.\n",
    "\n",
    "To develop your understanding of the domain, you are advised to independently research a little about risk analytics - understanding the types of variables and their significance should be enough)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <font color = blue> Business Objective </font>\n",
    "\n",
    "The loan providing companies find it hard to give loans to the people due to their insufficient or non-existent credit history. Because of that, some consumers use it as their advantage by becoming a defaulter. Suppose you work for a consumer finance company which specialises in lending various types of loans to urban customers. You have to use EDA to analyse the patterns present in the data. This will ensure that the applicants capable of repaying the loan are not rejected.\n",
    "\n",
    " \n",
    "\n",
    "When the company receives a loan application, the company has to decide for loan approval based on the applicant’s profile. Two types of risks are associated with the bank’s decision:\n",
    "\n",
    "If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n",
    "\n",
    "If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out the warnings\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#from sklearn.preprocessing import Standard\n",
    "import os # accessing directory structure\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Task 1: Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 1.1: Read the application Data.\n",
    "\n",
    "Read the application data and store it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file using 'read_csv'.\n",
    "\n",
    "data = pd.read_csv(\"application_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 1.2: Inspect the Dataframe\n",
    "\n",
    "Inspect the dataframe for dimensions, null-values, and summary of different numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns in the dataframe\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the column-wise info of the dataframe\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types of columns \n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the summary for the numeric columns \n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data types of columns same like info\n",
    "\n",
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the total count of the columns which is having Null values\n",
    "\n",
    "(data.isnull().sum()>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the sum of Null values for each columns\n",
    "\n",
    "sum_null = data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_null.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate the percentage of null columns\n",
    "\n",
    "percentage_null = data.isnull().mean()*100\n",
    "percentage_null = percentage_null.sort_values(ascending = False)\n",
    "percentage_null\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Data Cleaning and Manipluation\n",
    "\n",
    "Now that we have loaded the dataset and inspected it, we see Null values in many columns and calculated it's percentages respectively. Let's now work on handling these Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ###  Subtask 2.1: Visualizing the Percentage of the columns which is having Null values!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "null_col = percentage_null.sort_values(ascending = False)\n",
    "null_col = null_col[null_col>32]\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.title(\"Representation of Null columns vs their percentage\", fontdict = {\"fontsize\":26, \"fontweight\":20, \"color\":\"Green\"})\n",
    "plt.xlabel(\"Null columns\", fontdict = {\"fontsize\":25, \"fontweight\":20, \"color\":\"Green\"})\n",
    "plt.ylabel(\"Percentage\", fontdict = {\"fontsize\":25, \"fontweight\":20, \"color\":\"Green\"})\n",
    "null_col.plot.bar(color = 'purple');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the original dataframe to new dataframe called 'new_data' \n",
    "\n",
    "new_data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ###  Subtask 2.2: Removing the Null columns, having the percentage more than 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inspecting the null columns and found out that there is no significance reason to keep the null columns more than 32%, so, dropping those columns\n",
    "\n",
    "get_col = new_data.isnull().mean()*100\n",
    "get_col = get_col[get_col.values>=32].index.to_list()\n",
    "new_data.drop(labels = get_col,axis =1,inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the dataframe after dropping the null columns\n",
    "\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ###  Subtask 2.3: Handling Missing / Null values in each columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the null columns accordding to descending value\n",
    "\n",
    "(new_data.isnull().mean()*100).sort_values(ascending = False).head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',30751)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  #### 2.3.1: For the column 'OCCUPATION_TYPE', we can impute the most frequent category, i.e., 'Laborers', since it is a categorical coulmn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['OCCUPATION_TYPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_data[\"OCCUPATION_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data[\"OCCUPATION_TYPE\"].mode())\n",
    "\n",
    "# Impute the mode value\n",
    "\n",
    "new_data['OCCUPATION_TYPE'].fillna('Laborers', inplace = True)\n",
    "new_data['OCCUPATION_TYPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- #### 2.3.2: For the columns 'EXT_SOURCE_3', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'AMT_REQ_CREDIT_BUREAU_MONTH', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_QRT', we can impute the missing values of these columns with the mode value, which is '0'. We can see those columns are about the credit inquiries made by bank. So, imputing mode value seems to the good approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['EXT_SOURCE_3'] = new_data['EXT_SOURCE_3'].fillna(new_data['EXT_SOURCE_3'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_YEAR'] = new_data['AMT_REQ_CREDIT_BUREAU_YEAR'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_YEAR'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_MON'] = new_data['AMT_REQ_CREDIT_BUREAU_MON'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_MON'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_WEEK'] = new_data['AMT_REQ_CREDIT_BUREAU_WEEK'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_WEEK'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_DAY'] = new_data['AMT_REQ_CREDIT_BUREAU_DAY'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_DAY'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_HOUR'] = new_data['AMT_REQ_CREDIT_BUREAU_HOUR'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_HOUR'].mode()[0])\n",
    "new_data['AMT_REQ_CREDIT_BUREAU_QRT'] = new_data['AMT_REQ_CREDIT_BUREAU_QRT'].fillna(new_data['AMT_REQ_CREDIT_BUREAU_QRT'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again checking the Null values after imputing the above columns\n",
    "\n",
    "new_data.isnull().sum().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking info\n",
    "\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_data.isnull().mean()*100).sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-  #### 2.3.3: For the column 'NAME_TYPE_SUITE', we can impute the most frequent category, i.e., 'Laborers', since it is a categorical coulmn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_data[\"NAME_TYPE_SUITE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['NAME_TYPE_SUITE'].mode())\n",
    "new_data['NAME_TYPE_SUITE'] = new_data['NAME_TYPE_SUITE'].fillna(new_data['NAME_TYPE_SUITE'].mode()[0])\n",
    "new_data['NAME_TYPE_SUITE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.4: For the columns 'DEF_30_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',   'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', we can impute the most frequent category, i.e., '0', since these are all 'How many observation/defaulted of client's social surroundings with 30/60 DPD (days past due) default. So, this would be the  good approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['DEF_30_CNT_SOCIAL_CIRCLE'] = new_data['DEF_30_CNT_SOCIAL_CIRCLE'].fillna(new_data['DEF_30_CNT_SOCIAL_CIRCLE'].mode()[0])\n",
    "new_data['DEF_60_CNT_SOCIAL_CIRCLE'] = new_data['DEF_60_CNT_SOCIAL_CIRCLE'].fillna(new_data['DEF_60_CNT_SOCIAL_CIRCLE'].mode()[0])\n",
    "new_data['OBS_30_CNT_SOCIAL_CIRCLE'] = new_data['OBS_30_CNT_SOCIAL_CIRCLE'].fillna(new_data['OBS_30_CNT_SOCIAL_CIRCLE'].mode()[0])\n",
    "new_data['OBS_60_CNT_SOCIAL_CIRCLE'] = new_data['OBS_60_CNT_SOCIAL_CIRCLE'].fillna(new_data['OBS_60_CNT_SOCIAL_CIRCLE'].mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.5: Dropping the columns which starts with FLAG_DOCUMENT. Since, it doesn't contain any information about what type of docyments these are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['FLAG_DOCUMENT_3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_col = list(new_data.loc[:,'FLAG_DOCUMENT_2':'FLAG_DOCUMENT_21'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.drop(flag_col, inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum().sort_values(ascending = False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.6: For the column 'EXT_SOURCE_2', we can impute the most frequent value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['EXT_SOURCE_2'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['EXT_SOURCE_2'] = new_data['EXT_SOURCE_2'].fillna(new_data['EXT_SOURCE_2'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.7: For the column 'AMT_GOODS_PRICE', we can impute the median value, which is  '450000.0'. Since, this is a numeric columns with the skewness. Hence, this would be the best approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_GOODS_PRICE'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_GOODS_PRICE'] = new_data['AMT_GOODS_PRICE'].fillna(new_data['AMT_GOODS_PRICE'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.8: For the column 'AMT_ANNUITY', we can impute the median value, which is  '24903.0'. Since, this is a numeric columns with the skewness. Hence, this would be the best approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_ANNUITY'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_ANNUITY'] = new_data['AMT_ANNUITY'].fillna(new_data['AMT_ANNUITY'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.9: For the column 'CNT_FAM_MEMBERS', we can impute the mode value, which is  '2'. Since, this is a numeric columns with normalized value. Hence, this would be the best approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CNT_FAM_MEMBERS'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CNT_FAM_MEMBERS'] = new_data['CNT_FAM_MEMBERS'].fillna(new_data['CNT_FAM_MEMBERS'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  #### 2.3.10: For the column 'DAYS_LAST_PHONE_CHANGE', we can impute the median value, which is  '0'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['DAYS_LAST_PHONE_CHANGE'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['DAYS_LAST_PHONE_CHANGE'] = new_data['DAYS_LAST_PHONE_CHANGE'].fillna(new_data['DAYS_LAST_PHONE_CHANGE'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, that we have handled all the Null/Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum().sort_values(ascending = False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the shape of the dataframe\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the info\n",
    "\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing the data\n",
    "\n",
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Handling Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ####  Subtask 3.1: checking the unique values of the columns starts with \"DAYS\" and handling the negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(new_data['DAYS_BIRTH'].unique())\n",
    "print(new_data['DAYS_EMPLOYED'].unique())\n",
    "print(new_data['DAYS_REGISTRATION'].unique())\n",
    "print(new_data['DAYS_ID_PUBLISH'].unique())\n",
    "print(new_data['DAYS_LAST_PHONE_CHANGE'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the negative values to absolute values using abs function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE']] = abs(new_data[['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'DAYS_LAST_PHONE_CHANGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['DAYS_BIRTH'].unique())\n",
    "print(new_data['DAYS_EMPLOYED'].unique())\n",
    "print(new_data['DAYS_REGISTRATION'].unique())\n",
    "print(new_data['DAYS_ID_PUBLISH'].unique())\n",
    "print(new_data['DAYS_LAST_PHONE_CHANGE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ####  Subtask 3.1: There are some columns where the value is mentioned as 'XNA' which means 'Not Available'. So we have to find the number of rows and columns and implement suitable techniques on them to fill those missing values or to delete them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's find these categorical columns having these 'XNA' values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Gender column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CODE_GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['CODE_GENDER']=='XNA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['CODE_GENDER'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can replace the \"XNA\" of CODE_GENDER with mode value, Which is F(Female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['CODE_GENDER']=='XNA', 'CODE_GENDER'] = 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['CODE_GENDER'].unique())\n",
    "new_data['CODE_GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For ORGANIZATION_TYPE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['ORGANIZATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, for column 'ORGANIZATION_TYPE', we have total count of 307511 rows of which 55374 rows are having 'XNA' values. Which means 18% of the column is having this values. Hence we replace with 'NaN', will not have any major impact on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.replace('XNA',np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['ORGANIZATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:  Analysis of Continuous variables and binning when required.\n",
    "     \n",
    " Now our task is to analyze the continuous variable and creating the bins for the required categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Subtask 4.1: Analysis of 'DAYS_BIRTH' column. Here the days_birth column data is provided in days. Hence converting the days into years by dividing it in 365 days and Binning the 'DAYS_BIRTH' into 'Young','Adult', 'Middle_Aged', 'Senior_Citizen' and storing in a new variable called 'YEAR_BIRTH_BINNING'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of 'DAYS_BIRTH' column.\n",
    "\n",
    "new_data['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the days_birth column data is provided in days. Hence converting the days into years by dividing it into 365 days .\n",
    "\n",
    "new_data['DAYS_BIRTH']= (new_data['DAYS_BIRTH']/365).astype(int)\n",
    "new_data['YEAR_BIRTH_BINNING']= new_data['DAYS_BIRTH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['YEAR_BIRTH_BINNING'].unique())\n",
    "print(new_data['YEAR_BIRTH_BINNING'].min())\n",
    "print(new_data['YEAR_BIRTH_BINNING'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning the 'DAYS_BIRTH' into 'Young','Adult', 'Middle_Aged', 'Senior_Citizen' and storing in a new variable called 'YEAR_BIRTH_BINNING'\n",
    "\n",
    "new_data['YEAR_BIRTH_BINNING']=pd.cut(new_data['YEAR_BIRTH_BINNING'], bins=[18,25,35,60,100], labels=['Young','Adult', 'Middle_Aged', 'Senior_Citizen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEAR_BIRTH_BINNING'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Subtask 4.2: Here the DAYS_EMPLOYED column data is provided in days. Hence converting the days into years by dividing it into 365 days and storing it in a new variable 'YEARS_EMPLOYED'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the DAYS_EMPLOYED column data is provided in days. Hence converting the days into years by dividing it into 365 days and storing it in a new variable 'YEARS_EMPLOYED'\n",
    "\n",
    "new_data['YEARS_EMPLOYED'] = np.round(new_data.DAYS_EMPLOYED / 365, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEARS_EMPLOYED'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After converting the DAYS_EMPLOYED from days to years and stored it in a new variable YEARS_EMPLOYED.\n",
    "# we observed the years employed as 1000, which is practically impossible.\n",
    "# Hence replacing those values to 'NaN'\n",
    "\n",
    "new_data[new_data['YEARS_EMPLOYED']>=1000].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['YEARS_EMPLOYED'] >= 1000, 'YEARS_EMPLOYED'] = np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['YEARS_EMPLOYED'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Subtask 4.3: Binning the 'AMT_INCOME_TOTAL' column as 'VERY_LOW', 'LOW', \"MEDIUM\", 'HIGH', 'VERY_HIGH' and storing in a new variable called AMT_INCOME_TOTAL_RANGE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_INCOME_TOTAL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_INCOME_TOTAL_RANGE'] = pd.qcut(new_data.AMT_INCOME_TOTAL, q=[0, 0.2, 0.5, 0.8, 0.95, 1], labels=['VERY_LOW', 'LOW', \"MEDIUM\", 'HIGH', 'VERY_HIGH'])\n",
    "new_data['AMT_INCOME_TOTAL_RANGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_CREDIT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['AMT_CREDIT_RANGE'] = pd.qcut(new_data.AMT_CREDIT, q=[0, 0.2, 0.5, 0.8, 0.95, 1], labels=['VERY_LOW', 'LOW', \"MEDIUM\", 'HIGH', 'VERY_HIGH'])\n",
    "new_data['AMT_CREDIT_RANGE'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5:  Data Analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 5.1: Checking data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"To check the percentage of with payment difficulties vs Others\", color = 'green')\n",
    "new_data.TARGET.value_counts(normalize=True).plot.pie(autopct='%1.2f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)\n",
    "\n",
    "1)We can see from the above pie chart, the percentage of clients with payment difficulties is 8%\n",
    "\n",
    "2)the percentage of clients with non-payment difficulties is 92%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 5.2: Splitting Data with respect to TARGET=0 and TARGET=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = new_data[new_data.TARGET==1]\n",
    "target_0 = new_data[new_data.TARGET==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 5.3: Checking distribution of important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of 'YEARS_EMPLOYED' column\n",
    "\n",
    "plt.figure(figsize = [10,5])\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(new_data.YEARS_EMPLOYED, color = 'magenta');\n",
    "plt.title(\"Distribution of years employed\", fontdict = {'fontsize': 15, 'fontweight': 20, 'color' : 'brown'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1)We can observe that the column \"YEARS_EMPLOYED\" is normally distributed.\n",
    "\n",
    "2)The experience/years employed ranges from 0 to 50 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of 'DAYS_BIRTH' column\n",
    "\n",
    "plt.figure(figsize = [10,5])\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(new_data.DAYS_BIRTH, color = 'violet');\n",
    "plt.title(\"Distribution of Days Birth\", fontdict = {'fontsize': 15, 'fontweight': 20, 'color' : 'brown'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1)From the above graph, we can observe that, the column \"DAYS_BIRTH\" is normally distributed.\n",
    "\n",
    "2)The age ranges from 25 to 70 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of 'AMT_CREDIT' column\n",
    "\n",
    "plt.figure(figsize = [10,5])\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(new_data.AMT_CREDIT, color = 'violet');\n",
    "plt.title(\"Distribution of Days Amount credit\", fontdict = {'fontsize': 15, 'fontweight': 20, 'color' : 'brown'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1)From the above graph, we can observe that, the column \"AMT_CREDIT\" distribution curve does not appear to be normal or bell curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of 'AMT_ANNUITY' column\n",
    "\n",
    "plt.figure(figsize = [10,5])\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(new_data.AMT_ANNUITY, color = 'violet');\n",
    "plt.title(\"Distribution of AMT_ANNUITY\", fontdict = {'fontsize': 15, 'fontweight': 20, 'color' : 'brown'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1)From the above graph, we can observe that, the column \"AMT_ANNUITY\" distribution curve appear to be normal.\n",
    "\n",
    "2)And the curve is skewed to the right side of the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Distribution of 'AMT_GOODS_PRICE' column\n",
    "\n",
    "plt.figure(figsize = [10,5])\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.distplot(new_data.AMT_GOODS_PRICE, color = 'violet');\n",
    "plt.title(\"Distribution of AMT_GOODS_PRICE\", fontdict = {'fontsize': 15, 'fontweight': 20, 'color' : 'brown'})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1)From the above graph, we can observe that, the column \"AMT_GOODS_PRICE\" distribution curve does not appear to be normal or bell curve.\n",
    "\n",
    "2)However the curve is skewed to the right side of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn AMT_INCOME_TOTAL to find outliers\n",
    "\n",
    "fig = px.box(new_data, y=\"AMT_INCOME_TOTAL\", title=' Total Amount Income analysis')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.AMT_INCOME_TOTAL.quantile([.5, .7, .9, .95, 0.99, 0.999, 0.9999])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few points can be concluded from the graph above**\n",
    "\n",
    "Some outliers are noticed in income amount. The third quartiles is very slim for income amount. We can conclude that, the amount 117M observed from the box plot is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn YEARS_EMPLOYED to find outliers\n",
    "\n",
    "fig = px.box(new_data, y=\"YEARS_EMPLOYED\", title='Years Employed Analysis', notched=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.YEARS_EMPLOYED.quantile([.5, .7, .9, .95, 0.99, 0.999, 0.9999])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above plot**\n",
    "\n",
    "Here, in the coloumn 'DAYS_EMPLOYED' which tells how many days before the application the person started current employment. \n",
    "\n",
    "We don't see any outliers in this case, as we have already handled a, having the value 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn DAYS_BIRTH to find outliers\n",
    "\n",
    "fig = px.box(new_data, y=\"DAYS_BIRTH\", title='Days birth Analysis', notched = True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above plot**\n",
    "\n",
    "There is no outliers present in the age column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn AMT_CREDIT to find outliers\n",
    "\n",
    "fig = px.box(new_data, y=\"AMT_CREDIT\",  title='Amount credit Analysis', notched = True)\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few points can be concluded from the plot above**\n",
    "\n",
    "1) Some outliers are noticed in credit amount.\n",
    "\n",
    "2) The first quartile is bigger than third quartile for credit amount which means most of the credits of clients are present in the first quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn AMT_ANNUITY to find outliers\n",
    "\n",
    "fig = px.box(new_data, y=\"AMT_ANNUITY\", title='Amount Annuity Analysis', notched = True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data.AMT_ANNUITY.quantile([.5, .7, .9, .95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few points can be concluded from the graph above**\n",
    "\n",
    "1) Some outliers are noticed in annuity amount.\n",
    "\n",
    "2) The first quartile is bigger than third quartile for annuity amount which means most of the annuity clients are from first quartile.\n",
    "\n",
    "3)The value above 258000 is an outlier here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis on coulmn AMT_GOODS_PRICE to find outliers\n",
    "\n",
    "\n",
    "fig = px.box(new_data, y=\"AMT_GOODS_PRICE\",title='AMT_GOODS_PRICE Analysis', notched = True)\n",
    "\n",
    "fig.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.AMT_GOODS_PRICE.quantile([.5, .7, .9, .95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Few points could be concluded from the above plot**\n",
    "\n",
    "1)For consumer loans it is the price of the goods for which the loan is given.\n",
    "\n",
    "2)Some outliers are noticed in Goods price. \n",
    "\n",
    "3) The first quartile is bigger than third quartile for goods amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'OCCUPATION_TYPE'\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "plt.title(\"The distribution of occupation- applied for loan\", fontdict = {\"fontsize\":20, \"fontweight\":20, \"color\":\"blue\"})\n",
    "plt.xlabel(\"Occupation\", fontdict = {\"fontsize\":15, \"fontweight\":20, \"color\":\"brown\"})\n",
    "plt.ylabel(\"count\", fontdict = {\"fontsize\":15, \"fontweight\":20, \"color\":\"brown\"})\n",
    "new_data['OCCUPATION_TYPE'].value_counts().plot.bar(color = 'violet')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above chart**\n",
    "\n",
    "    1) 3 categories, 'Laborers', 'Sales staff', 'Core staffs' shows the major count, who applied \n",
    "    for loan.\n",
    "    2) IT Staffs are the least applied for the loan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 5.4: Univariate Analysis\n",
    "\n",
    "Here we will analysis the single variables for target1 and target2 by parallel plotting and will make an inference.\n",
    "\n",
    "Note that, we already segregated the target1 and target2 variables on subtask 5.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to Visualization the target1 target0 variables\n",
    "\n",
    "def distribution(col, label_rotation = True,horizontal_layout= True, hue = None):\n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n",
    "    \n",
    "    s1 = sns.countplot(ax = ax1, data = target_1, x= target_1[col], order=target_1[col].value_counts().index,hue = hue,palette='magma') \n",
    "    if(label_rotation):\n",
    "        s1.set_xticklabels(s1.get_xticklabels(),rotation = 90)\n",
    "    ax1.set_xlabel('%s' %col)\n",
    "    ax1.set_ylabel(\"Count\")\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    \n",
    "    ax1.set_title('Distribution of '+ '%s' %col +' for clients with payment difficulties', fontsize=10)\n",
    "\n",
    "\n",
    "    \n",
    "    s2 = sns.countplot(ax = ax2, data = target_0, x= target_0[col], order=target_0[col].value_counts().index,hue = hue,palette='magma') \n",
    "    #s2=sns.countplot(ax=ax2,x=nondefaulters[var], data=nondefaulters, order= nondefaulters[var].value_counts().index,)\n",
    "    if(label_rotation):\n",
    "        s2.set_xticklabels(s2.get_xticklabels(),rotation=45)\n",
    "    ax2.set_xlabel('%s' %col)\n",
    "    ax2.set_ylabel(\"Count\")\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "    ax2.set_title('Distribution of '+ '%s' %col +' for clients with Non-payment difficulties', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_INCOME_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_INCOME_TYPE', hue='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) Clients who are either at Maternity leave OR Unemployed have payment difficulties\n",
    "\n",
    "2) For this,  Females are having more number of credits than male.\n",
    "\n",
    "3) Student and Businessmen have no defaults "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_EDUCATION_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_EDUCATION_TYPE', hue='CODE_GENDER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "\n",
    "1) The count of Loan Payment Difficulties whose educational qualifications secondary/secondary special is higher compared to higher education, Incomplete higher.\n",
    "\n",
    "2) And for those who has completed/studying Academic degree has no payments difficulties.\n",
    "\n",
    "3) The Females are having more number of credits than male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal varaibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_TYPE_SUITE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_TYPE_SUITE', hue='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) The count of Loan Payment Difficulties is higher for 'Unaccompanied' than rest other cases.\n",
    "\n",
    "2) For the categories like Other_A and Group of prople has no payments difficulties.\n",
    "\n",
    "3) The Females are having more number of credits than male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_FAMILY_STATUS\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_FAMILY_STATUS', hue='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) And decrease in count for separated and widow with Loan Payment Difficulties when comapred with the percentages from both the charts.\n",
    "\n",
    "2) clients who have civil marriage or who are single default a lot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_HOUSING_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_HOUSING_TYPE', hue='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) We can conclude from the chart, that the Most people live in a House/Apartment\n",
    "\n",
    "2) Ratio of People who live With Parents is more for defaulter than non-defaulters. \n",
    "\n",
    "3) We infer that the applicants who live with parents have a higher chance of having payment difficulties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"NAME_CONTRACT_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution('NAME_CONTRACT_TYPE', hue='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) For contract type ‘cash loans’ is having higher number of credits than ‘Revolving loans’ contract type.\n",
    "\n",
    "2) For this also Female is leading for applying credits.\n",
    "\n",
    "3) For type 1 : there is only Female Revolving loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot to see the distrubution of \"OCCUPATION_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.subplot(1,2,1)\n",
    "\n",
    "a1 = target_1[~(target_1.OCCUPATION_TYPE == 'Others')]\n",
    "ax = (a1['OCCUPATION_TYPE'].value_counts(normalize = True)*100).plot.bar(color = 'green')\n",
    "plt.title(\"Clients with payment difficulties\", fontdict = {\"fontsize\":13, \"fontweight\":20, \"color\":\"brown\"})\n",
    "plt.ylabel(\"Percentage\", fontdict = {'fontsize': 12, 'fontweight': 20, 'color': 'brown'})\n",
    "ticks = np.arange(0, 40, 5)\n",
    "labels = [\"{}%\".format(i) for i in ticks]\n",
    "plt.yticks(ticks, labels, rotation = 0)\n",
    "plt.xticks(rotation = 90)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                 textcoords = 'offset points')\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "b1 = target_0[~(target_0.OCCUPATION_TYPE == 'Others')]\n",
    "ax = (b1['OCCUPATION_TYPE'].value_counts(normalize = True)*100).plot.bar(color = 'orange')\n",
    "plt.title(\"clients with no payment difficulties\", fontdict = {\"fontsize\":13, \"fontweight\":20, \"color\":\"brown\"})\n",
    "plt.ylabel(\"Percentage\", fontdict = {'fontsize': 12, 'fontweight': 20, 'color': 'brown'})\n",
    "ticks = np.arange(0, 40, 5)\n",
    "labels = [\"{}%\".format(i) for i in ticks]\n",
    "plt.yticks(ticks, labels, rotation = 0)\n",
    "plt.xticks(rotation = 90)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                 textcoords = 'offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above chart**\n",
    "\n",
    "1) 3 categories, 'Laborers', 'Sales staff', 'Core staffs' shows the major count, who applied for loan are having the more percentage of payment difficulties.\n",
    "\n",
    "2) IT Staffs are the least applied for the loan and non-defaulters in both the cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting for Organization type in logarithmic scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "plt.title(\"Distribution of Organization type for target - 1\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "sns.countplot(data=target_1,y='ORGANIZATION_TYPE',order=target_1['ORGANIZATION_TYPE'].value_counts().index,palette='cubehelix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,30))\n",
    "plt.title(\"Distribution of Organization type for target - 0\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "sns.countplot(data=target_0,y='ORGANIZATION_TYPE',order=target_0['ORGANIZATION_TYPE'].value_counts().index,palette='cubehelix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) Clients which have applied for credits are from most of the organization type ‘Business entity Type 3’ , ‘Self employed’ , ‘Other’ , ‘Medicine’ and ‘Government’.\n",
    "\n",
    "2) Less clients are from Industry type 8,type 6, type 10, religion and trade type 5, type 4.\n",
    "\n",
    "3) Same as type 0 in distribution of organization type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pie chart to see the % of \"OCCUPATION_TYPE\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax1 = target_1['CODE_GENDER'].value_counts()\n",
    "ind = ax1.index\n",
    "val = ax1.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n With payment difficulties \\n\")])\n",
    "fig.show()\n",
    "\n",
    "ax2 = target_0['CODE_GENDER'].value_counts()\n",
    "ind = ax2.index\n",
    "val = ax2.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n Non payment difficulties \\n\")])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above chart**\n",
    "\n",
    "1) We can make an inference from the above chart, that the number of Females taking loans is much higher than the number of Males for both the cases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete variable - Binned variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pie chart to see the % of \"YEAR_BIRTH_BINNING\" with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax1 = target_1['YEAR_BIRTH_BINNING'].value_counts()\n",
    "ind = ax1.index\n",
    "val = ax1.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n payment difficulties \\n\")])\n",
    "fig.show()\n",
    "\n",
    "ax2 = target_0['YEAR_BIRTH_BINNING'].value_counts()\n",
    "ind = ax2.index\n",
    "val = ax2.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n Non payment difficulties \\n\")])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be concluded from the above graph**\n",
    "\n",
    "1) We can see from the graph, that there is an increase in the percentage of Loan Payment Difficulties who are young in age when compared to the percentages of Payment Difficulties and Loan-Non Payment Difficulties from 5% to 7 %\n",
    "\n",
    "2) The same is applicabe to Adults also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pie chart to see the % of   \"AMT_INCOME_TOTAL_RANGE\"   with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax1 = target_1['AMT_INCOME_TOTAL_RANGE'].value_counts()\n",
    "ind = ax1.index\n",
    "val = ax1.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n With payment difficulties \\n\")])\n",
    "fig.show();\n",
    "\n",
    "ax2 = target_0['AMT_INCOME_TOTAL_RANGE'].value_counts()\n",
    "ind = ax2.index\n",
    "val = ax2.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n Non payment difficulties \\n\")])\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to be concluded from the above graph\n",
    "\n",
    "1) We can see from the graph, that there is an increase in the percentage of Loan Payment Difficulties for 'Medium' and 'Low' Income when compared to the other case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pie chart to see the % of   \"AMT_CREDIT_RANGE\"   with payments difficulties vs Non-payments difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = target_1['AMT_CREDIT_RANGE'].value_counts()\n",
    "ind = ax1.index\n",
    "val = ax1.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n With payment difficulties \\n\")])\n",
    "fig.show()\n",
    "\n",
    "ax2 = target_0['AMT_CREDIT_RANGE'].value_counts()\n",
    "ind = ax2.index\n",
    "val = ax2.values\n",
    "fig = go.Figure(data=[go.Pie(labels=ind, values=val, title = \"\\n Non payment difficulties \\n\")])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to be concluded from the above graph\n",
    "\n",
    "1) We can see from the graph, that there is an increase in the percentage of Loan Payment Difficulties for 'Medium' and 'Low' credit when compared to the other case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  Subtask 5.4: Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5.4.1 Bivariate Analysis of Categorical vs Numerical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Payment difficulties - NAME_INCOME_TYPE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(target_1, x=\"NAME_INCOME_TYPE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"Income type vs Amount Credit - Non-Loan Payment Difficulties\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Payment difficulties - NAME_INCOME_TYPE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(target_0, x=\"NAME_INCOME_TYPE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"Income type vs Amount Credit - Loan Payment Difficulties\", notched = True) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above plot**\n",
    "\n",
    "1) The plot for Loan Payment/non-Payment looks almost similar\n",
    "\n",
    "2) The categories like 'Pensioner' and 'State Service' have credits decrease, which means they have low payment difficulties. \n",
    "\n",
    "3) We can also notice there are outliers present and for the commercial Associate the outliers value is very huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Payment difficulties - AMT_INCOME_TOTAL_RANGE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(target_1, x=\"AMT_INCOME_TOTAL_RANGE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"AMT_INCOME_TOTAL_RANGE vs AMT_CREDIT - Payment Difficulties\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non- Payment difficulties - AMT_INCOME_TOTAL_RANGE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(target_0, x=\"AMT_INCOME_TOTAL_RANGE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"AMT_INCOME_TOTAL_RANGE vs AMT_CREDIT --- Non-Payment Difficulties\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above chart**\n",
    "\n",
    "1) Both the plots appears to be similar.\n",
    "\n",
    "2) We can see that, the  Family status of 'single', 'seperated' and 'married' of income range very-high are having higher number of credits than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment difficulties - NAME_EDUCATION_TYPE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(target_1, x=\"NAME_EDUCATION_TYPE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"NAME_EDUCATION_TYPE vs AMT_CREDIT - Payment Difficulties\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non- Payment difficulties - NAME_EDUCATION_TYPE vs AMT_CREDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'NAME_EDUCATION_TYPE' vs 'AMT_CREDIT' for Loan - Non Payment Difficulties\n",
    "\n",
    "fig = px.box(target_1, x=\"NAME_EDUCATION_TYPE\", y=\"AMT_CREDIT\", color='NAME_FAMILY_STATUS',\n",
    "             title=\"NAME_EDUCATION_TYPE vs AMT_CREDIT - Payment Difficulties\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference from the above chart**\n",
    "\n",
    "1) Quite similar with Target 0 From the above box plot we can say that Family status of 'civil marriage', 'marriage' and 'separated' of Academic degree education are having higher number of credits than others. \n",
    "\n",
    "2) Most of the outliers are from Education type 'Higher education' and 'Secondary'. Civil marriage for Academic degree is having most of the credits in the third quartile.\n",
    "\n",
    "3) Females are having high payment difficulties than male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot to see the Payment difficulties - AMT_INCOME_TOTAL vs OCCUPATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(target_1.OCCUPATION_TYPE, target_1.AMT_INCOME_TOTAL)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Payment difficulties - Amt_Income_total vs Occupation_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot to see the non - Payment difficulties - AMT_INCOME_TOTAL vs OCCUPATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(target_0.OCCUPATION_TYPE, target_0.AMT_INCOME_TOTAL)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Non-Payment difficulties - Amt_Income_total vs Occupation_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences to be made from the above chart**\n",
    "\n",
    "1) Here we see that both the graphs looks almost similar.\n",
    "\n",
    "2) The income for managers is very high compared to other categories, who don't defaults.\n",
    "\n",
    "3) The probability of payments difficulties is high for Laborers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5.4.2 Bivariate Analysis of Categorical vs Categorical Variables\n",
    "\n",
    "Here we have defined the function analyse the TARGET. i.e., payment difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function\n",
    "\n",
    "def stat_chart(feature,label_rotation=True,horizontal_layout=True):\n",
    "    temp_data = new_data[feature].value_counts()\n",
    "    df1 = pd.DataFrame({feature: temp_data.index,'count': temp_data.values})\n",
    "\n",
    "    # percentage of target=1 \n",
    "    per = new_data[[feature, 'TARGET']].groupby([feature],as_index=False).mean()\n",
    "    per.sort_values(by='TARGET', ascending=False, inplace=True)\n",
    "    \n",
    "    if(horizontal_layout):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14))\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    s = sns.barplot(ax=ax1, x = feature, y=\"count\",data=df1)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=per[feature], data=per)\n",
    "    if(label_rotation):\n",
    "        s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "    plt.ylabel('Percentage', fontsize=10)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_EDUCATION_TYPE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('NAME_EDUCATION_TYPE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) From the above plot, we can infer that, clients with 'Lower secondary' education type have maximum percentage of Loan-Payment Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_CONTRACT_TYPE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('NAME_CONTRACT_TYPE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Cash loans' contract type have maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE_GENDER with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('CODE_GENDER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Males' have maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLAG_OWN_CAR with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('FLAG_OWN_CAR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'car' have less percentage of Loan Payemnt Difficulties than the clients with no cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_TYPE_SUITE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('NAME_TYPE_SUITE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Other-B' have maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_INCOME_TYPE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('NAME_INCOME_TYPE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Maternity leave' category have maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAME_EDUCATION_TYPE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('NAME_EDUCATION_TYPE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Lower secondary' type have maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OCCUPATION_TYPE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('OCCUPATION_TYPE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Low skilled Laborers' category have the maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DAYS_BIRTH_BINNING_CATEGORIES with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('YEAR_BIRTH_BINNING')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Young' people have the maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMT_INCOME_TOTAL_RANGE with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('AMT_INCOME_TOTAL_RANGE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with 'Low' income have the maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNT_FAM_MEMBERS with maximum Loan-Payment Difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_chart('CNT_FAM_MEMBERS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "1) The above plot says that, the clients with '11 family members' category have the maximum percentage of Loan Payemnt Difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5.4.3 Bivariate Analysis of Numerical vs Numerical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerc = target_0[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL','DAYS_EMPLOYED', 'AMT_GOODS_PRICE', 'DAYS_BIRTH']]\n",
    "sns.pairplot(numerc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerc = target_1[['AMT_CREDIT', 'AMT_ANNUITY', 'AMT_INCOME_TOTAL','DAYS_EMPLOYED', 'AMT_GOODS_PRICE', 'DAYS_BIRTH']]\n",
    "sns.pairplot(numerc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences**\n",
    "\n",
    "- Credit amount is inversely proportional to the date of birth, which means Credit amount is higher for low age and vice-versa.\n",
    "\n",
    "- AMT_CREDIT and AMT_GOODS_PRICE are highly correlated in both the cases (target0 and target1)\n",
    "\n",
    "\n",
    "- AMT_CREDIT having greater credit value has less difficulties in repaying the loan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 5.4.4 Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding some correlation for numerical columns for both target 0 and 1 \n",
    "\n",
    "target1_corr=target_1[[\"CNT_CHILDREN\", \"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"REGION_POPULATION_RELATIVE\",\"DAYS_BIRTH\", \"DAYS_EMPLOYED\", \"DAYS_REGISTRATION\", \"DAYS_ID_PUBLISH\", \"HOUR_APPR_PROCESS_START\", \"REG_REGION_NOT_LIVE_REGION\", \"REG_REGION_NOT_WORK_REGION\", \"LIVE_REGION_NOT_WORK_REGION\", \"REG_CITY_NOT_LIVE_CITY\", \"REG_CITY_NOT_WORK_CITY\", \"LIVE_CITY_NOT_WORK_CITY\"]]\n",
    "target0_corr=target_0[[\"CNT_CHILDREN\", \"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"REGION_POPULATION_RELATIVE\",\"DAYS_BIRTH\", \"DAYS_EMPLOYED\", \"DAYS_REGISTRATION\", \"DAYS_ID_PUBLISH\", \"HOUR_APPR_PROCESS_START\", \"REG_REGION_NOT_LIVE_REGION\", \"REG_REGION_NOT_WORK_REGION\", \"LIVE_REGION_NOT_WORK_REGION\", \"REG_CITY_NOT_LIVE_CITY\", \"REG_CITY_NOT_WORK_CITY\", \"LIVE_CITY_NOT_WORK_CITY\"]]\n",
    "\n",
    "target0=target0_corr.corr(method='spearman')\n",
    "target1=target1_corr.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, plotting the above correlation with heat map as it is the best choice to visulaize\n",
    "\n",
    "# figure size\n",
    "\n",
    "def targets_corr(data,title):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.rcParams['axes.titlesize'] = 25\n",
    "    plt.rcParams['axes.titlepad'] = 70\n",
    "\n",
    "# heatmap with a color map of choice\n",
    "\n",
    "\n",
    "    sns.heatmap(data, cmap=\"YlGnBu\",annot=True)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Target 0\n",
    "\n",
    "targets_corr(data=target0,title='Correlation for target 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "As we can see from above correlation heatmap, There are number of observation we can point out\n",
    "\n",
    "1) Credit amount is inversely proportional to the date of birth, which means Credit amount is higher for low age and vice-versa.\n",
    "\n",
    "2) Credit amount is inversely proportional to the number of children client have, means Credit amount is higher for less children count client have and vice-versa.\n",
    "\n",
    "3) Income amount is inversely proportional to the number of children client have, means more income for less children client have and vice-versa.\n",
    "\n",
    "4) less children client have in densely populated area.\n",
    "\n",
    "5) Credit amount is higher to densely populated area.\n",
    "\n",
    "6) The income is also higher in densely populated area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Target 1\n",
    "\n",
    "targets_corr(data=target1,title='Correlation for target 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "\n",
    "This heat map for Target 1 is also having quite a same observation just like Target 0. But for few points are different. They are listed below.\n",
    "\n",
    "1) The client's permanent address does not match contact address are having less children and vice-versa\n",
    "\n",
    "2) The client's permanent address does not match work address are having less children and vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To find top 10 correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the columns\n",
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 10 correlation for target 0 (clients with no payment difficulties)\n",
    "corr = target_0[['AMT_INCOME_TOTAL','AMT_CREDIT', 'CNT_FAM_MEMBERS','AMT_GOODS_PRICE','AMT_ANNUITY','DAYS_EMPLOYED','DAYS_BIRTH', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'YEARS_EMPLOYED', 'REGION_RATING_CLIENT']].corr()\n",
    "\n",
    "corr_tar0 = target_0[['AMT_INCOME_TOTAL','AMT_CREDIT', 'CNT_FAM_MEMBERS','AMT_GOODS_PRICE','AMT_ANNUITY','DAYS_EMPLOYED','DAYS_BIRTH', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'YEARS_EMPLOYED', 'REGION_RATING_CLIENT']].corr()\n",
    "corr_tar0=corr_tar0.where(np.triu(np.ones(corr_tar0.shape),k=1).astype(np.bool))\n",
    "corr_df=corr_tar0.unstack().reset_index()\n",
    "corr_df.columns = ['VAR1','VAR2','CORRELATION']\n",
    "corr_df.dropna(subset=['CORRELATION'],inplace=True)\n",
    "corr_df['CORR_ABS']=corr_df['CORRELATION'].abs()\n",
    "\n",
    "# Sorting the values\n",
    "\n",
    "corr_df.sort_values('CORR_ABS', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences from the above heatmap**\n",
    "\n",
    "1) We can see that, there is a high correlation between credit amount and goods price.\n",
    "\n",
    "2) There is high correlation for annuity and total income.\n",
    "\n",
    "2) Defaulters have low correlation in number of years employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 10 correlation for target 0 (clients with no payment difficulties)\n",
    "\n",
    "corr = target_1[['AMT_INCOME_TOTAL','AMT_CREDIT', 'CNT_FAM_MEMBERS','AMT_GOODS_PRICE','AMT_ANNUITY','DAYS_EMPLOYED','DAYS_BIRTH', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'YEARS_EMPLOYED', 'REGION_RATING_CLIENT']].corr()\n",
    "\n",
    "corr_tar1 = target_1[['AMT_INCOME_TOTAL','AMT_CREDIT', 'CNT_FAM_MEMBERS','AMT_GOODS_PRICE','AMT_ANNUITY','DAYS_EMPLOYED','DAYS_BIRTH', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'YEARS_EMPLOYED', 'REGION_RATING_CLIENT']].corr()\n",
    "corr_tar1=corr_tar1.where(np.triu(np.ones(corr_tar1.shape),k=1).astype(np.bool))\n",
    "corr_df=corr_tar1.unstack().reset_index()\n",
    "corr_df.columns = ['VAR1','VAR2','CORRELATION']\n",
    "corr_df.dropna(subset=['CORRELATION'],inplace=True)\n",
    "corr_df['CORR_ABS']=corr_df['CORRELATION'].abs()\n",
    "\n",
    "# Sorting the values\n",
    "\n",
    "corr_df.sort_values('CORR_ABS', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, annot=False, cmap='ocean_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences**\n",
    "\n",
    "1) We can see that, there is a high correlation between credit amount and goods price. \n",
    "\n",
    "2) There appears to be some deviancies in the correlation of defaulter and no defaulters such as credit amount vs income.\n",
    "\n",
    "3) The loan annuity correlation with credit amount has reduced a little for clients with payment difficulties.\n",
    "\n",
    "4) We can also infer from the above heatmap that, the correlation high for years employed when compared with clients who falls under taget 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Analysing  previous application\n",
    "\n",
    "Here we are anlaysing the prevoius application data and making inferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the previous application data and store it in a dataframe.\n",
    "\n",
    "df1=pd.read_csv(\"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the missing data\n",
    "\n",
    "# listing the null values columns having more than 30%\n",
    "\n",
    "emptycol1=df1.isnull().sum()\n",
    "emptycol1=emptycol1[emptycol1.values>(0.3*len(emptycol1))]\n",
    "len(emptycol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing those 15 columns\n",
    "\n",
    "emptycol1 = list(emptycol1[emptycol1.values>=0.3].index)\n",
    "df1.drop(labels=emptycol1,axis=1,inplace=True)\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the column values of 'XNA' and 'XAP'\n",
    "df1=df1.drop(df1[df1['NAME_CASH_LOAN_PURPOSE']=='XNA'].index)\n",
    "df1=df1.drop(df1[df1['NAME_CASH_LOAN_PURPOSE']=='XNA'].index)\n",
    "df1=df1.drop(df1[df1['NAME_CASH_LOAN_PURPOSE']=='XAP'].index)\n",
    "\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merging the Application dataset with previous appliaction dataset\n",
    "\n",
    "new_df=pd.merge(left=new_data,right=df1,how='inner',on='SK_ID_CURR',suffixes='_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming cols after merging is done\n",
    "\n",
    "new_df1 = new_df.rename({'NAME_CONTRACT_TYPE_' : 'NAME_CONTRACT_TYPE','AMT_CREDIT_':'AMT_CREDIT','AMT_ANNUITY_':'AMT_ANNUITY',\n",
    "                         'WEEKDAY_APPR_PROCESS_START_' : 'WEEKDAY_APPR_PROCESS_START',\n",
    "                         'HOUR_APPR_PROCESS_START_':'HOUR_APPR_PROCESS_START','NAME_CONTRACT_TYPEx':'NAME_CONTRACT_TYPE_PREV',\n",
    "                         'AMT_CREDITx':'AMT_CREDIT_PREV','AMT_ANNUITYx':'AMT_ANNUITY_PREV',\n",
    "                         'WEEKDAY_APPR_PROCESS_STARTx':'WEEKDAY_APPR_PROCESS_START_PREV',\n",
    "                         'HOUR_APPR_PROCESS_STARTx':'HOUR_APPR_PROCESS_START_PREV'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted columns for analysis\n",
    "new_df1.drop(['SK_ID_CURR','WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START','REG_REGION_NOT_LIVE_REGION', \n",
    "              'REG_REGION_NOT_WORK_REGION','LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
    "              'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY','WEEKDAY_APPR_PROCESS_START_PREV',\n",
    "              'HOUR_APPR_PROCESS_START_PREV', 'FLAG_LAST_APPL_PER_CONTRACT','NFLAG_LAST_APPL_IN_DAY'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(new_df1.NAME_CONTRACT_STATUS)\n",
    "plt.xlabel(\"Contract Status\")\n",
    "plt.ylabel(\"Count of Contract Status\")\n",
    "plt.title(\"Distribution of Contract Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved=new_df1[new_df1.NAME_CONTRACT_STATUS=='Approved']\n",
    "refused=new_df1[new_df1.NAME_CONTRACT_STATUS=='Refused']\n",
    "canceled=new_df1[new_df1.NAME_CONTRACT_STATUS=='Canceled']\n",
    "unused=new_df1[new_df1.NAME_CONTRACT_STATUS=='Unused Offer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func(var):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,5))\n",
    "    \n",
    "    s1=sns.countplot(ax=ax1,x=refused[var], data=refused, order= refused[var].value_counts().index,)\n",
    "    ax1.set_title(\"Refused\", fontsize=10)\n",
    "    ax1.set_xlabel('%s' %var)\n",
    "    ax1.set_ylabel(\"Count of Loans\")\n",
    "    s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s2=sns.countplot(ax=ax2,x=approved[var], data=approved, order= approved[var].value_counts().index,)\n",
    "    s2.set_xticklabels(s2.get_xticklabels(),rotation=90)\n",
    "    ax2.set_xlabel('%s' %var)\n",
    "    ax2.set_ylabel(\"Count of Loans\")\n",
    "    ax2.set_title(\"Approved\", fontsize=10)\n",
    "    s3=sns.countplot(ax=ax3,x=canceled[var], data=canceled, order= canceled[var].value_counts().index,)\n",
    "    ax3.set_title(\"Canceled\", fontsize=10)\n",
    "    ax3.set_xlabel('%s' %var)\n",
    "    ax3.set_ylabel(\"Count of Loans\")\n",
    "    s3.set_xticklabels(s3.get_xticklabels(),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_func('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refused.TARGET.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approved.TARGET.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canceled.TARGET.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func1(var):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(15,5))\n",
    "    \n",
    "    s1=sns.scatterplot(x='AMT_CREDIT',y='AMT_GOODS_PRICE',data=approved)\n",
    "    ax1.set_title(\"Refused\", fontsize=10)\n",
    "    ax1.set_xlabel('%s' %var)\n",
    "    ax1.set_ylabel(\"Count of Loans\")\n",
    "    s1.set_xticklabels(s1.get_xticklabels(),rotation=90)\n",
    "    \n",
    "    s2=sns.scatterplot(x='AMT_CREDIT',y='AMT_GOODS_PRICE',data=refused)\n",
    "    s2.set_xticklabels(s2.get_xticklabels(),rotation=90)\n",
    "    ax2.set_xlabel('%s' %var)\n",
    "    ax2.set_ylabel(\"Count of Loans\")\n",
    "    ax2.set_title(\"Approved\", fontsize=10)\n",
    "    \n",
    "    \n",
    "    s3=sns.scatterplot(x='AMT_CREDIT',y='AMT_GOODS_PRICE',data=cancelled)\n",
    "    ax3.set_title(\"Canceled\", fontsize=10)\n",
    "    ax3.set_xlabel('%s' %var)\n",
    "    ax3.set_ylabel(\"Count of Loans\")\n",
    "    s3.set_xticklabels(s3.get_xticklabels(),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.scatterplot(x='AMT_APPLICATION',y='AMT_INCOME_TOTAL',data=refused)\n",
    "plt.title('Refused')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.scatterplot(x='AMT_APPLICATION',y='AMT_INCOME_TOTAL',data=approved)\n",
    "plt.title('Approved')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**\n",
    "\n",
    "Loan request higher than 200k had a higher rejection rate. Also loan rejection rate was much lower if the income was higher than 500k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing univariate analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of contract status in logarithmic scale\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plt.rcParams[\"axes.labelsize\"] = 20\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.titlepad'] = 30\n",
    "plt.xticks(rotation=90)\n",
    "plt.xscale('log')\n",
    "plt.title('Distribution of contract status with purposes')\n",
    "ax = sns.countplot(data = new_df1, y= 'NAME_CASH_LOAN_PURPOSE', \n",
    "                   order=new_df1['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue = 'NAME_CONTRACT_STATUS',palette='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points to be concluded from above plot:\n",
    "\n",
    "1) Most rejection of loans came from purpose 'repairs'.\n",
    "\n",
    "2) For education purposes we have equal number of approves and rejection\n",
    "\n",
    "3) Paying other loans and buying a new car is having significant higher rejection than approves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of contract status\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')\n",
    "\n",
    "plt.figure(figsize=(15,30))\n",
    "plt.rcParams[\"axes.labelsize\"] = 20\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['axes.titlepad'] = 30\n",
    "plt.xticks(rotation=90)\n",
    "plt.xscale('log')\n",
    "plt.title('Distribution of purposes with target ')\n",
    "ax = sns.countplot(data = new_df1, y= 'NAME_CASH_LOAN_PURPOSE', \n",
    "                   order=new_df1['NAME_CASH_LOAN_PURPOSE'].value_counts().index,hue = 'TARGET',palette='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few points we can conclude from abpve plot:\n",
    "\n",
    "1) Loan purposes with 'Repairs' are facing more difficulites in payment on time.\n",
    "\n",
    "2) There are few places where loan payment is significant higher than facing difficulties. They are 'Buying a garage', 'Business developemt', 'Buying land','Buying a new car' and 'Education' Hence we can focus on these purposes for which the client is having for minimal payment difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing bivariate analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plotting for Credit amount in logarithmic scale\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "plt.yscale('log')\n",
    "sns.boxplot(data =new_df1, x='NAME_CASH_LOAN_PURPOSE',hue='NAME_INCOME_TYPE',y='AMT_CREDIT_PREV',orient='v')\n",
    "plt.title('Prev Credit amount vs Loan Purpose')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can conclude some points-\n",
    "\n",
    "1) The credit amount of Loan purposes like 'Buying a home','Buying a land','Buying a new car' and'Building a house' is higher.\n",
    "\n",
    "2) Income type of state servants have a significant amount of credit applied\n",
    "\n",
    "3) Money for third person or a Hobby is having less credits applied for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Box plotting for Credit amount prev vs Housing type in logarithmic scale\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(data =new_df1, y='AMT_CREDIT_PREV',hue='TARGET',x='NAME_HOUSING_TYPE')\n",
    "plt.title('Prev Credit amount vs Housing type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for Housing type, office appartment is having higher credit of target 0 and co-op apartment is having higher credit of target 1. So, we can conclude that bank should avoid giving loans to the housing type of co-op apartment as they are having difficulties in payment. Bank can focus mostly on housing type with parents or House\\appartment or miuncipal appartment for successful payments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analysing the application data and previous data, we can conclude from the observations made on various parameters/columns and find out the attributes which can be repayer or defaulters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the few observed Metrices that clients falls under repayer category:\n",
    "\n",
    "\n",
    " - DAYS_BIRTH: Clients having age 50 or above are likely to fall under less defaulter’s category\n",
    " \n",
    " \n",
    " - NAME_INCOME_TYPE: We have inferred that, the Student and Businessmen category have no defaults.\n",
    " \n",
    " \n",
    " - DAYS_EMPLOYED: Clients with a greater number of experiences has the less probability to default.\n",
    " \n",
    " \n",
    " - AMT_INCOME_TOTAL: Clients having income more, has very less history of defaulters.\n",
    " \n",
    " \n",
    " - NAME_CASH_LOAN_PURPOSE: Loans bought for Hobby, Buying garage are being replayed mostly. \n",
    " \n",
    " \n",
    " - CNT_CHILDREN: Clients with less child or less family members show the pattern of less defaulters \n",
    " \n",
    " \n",
    " - NAME_EDUCATION_TYPE: People with Academic degree has less defaults.\n",
    "\n",
    " \n",
    " \n",
    " - CNT_CHILDREN: Clients with less child or less family members shows the pattern of less defaulters\n",
    " \n",
    "\n",
    " \n",
    " - ORGANIZATION_TYPE: Clients with Trade Type 4 and 5 and Industry type 8 have shown the pattern, that they are paying their loans properly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are the few observed metrices that clients falls under defaulter category:\n",
    "\n",
    "\n",
    "- OCCUPATION_TYPE: Low-skill Laborers, Drivers, Security staff, Laborers and Cooking staff, these people are having high payment difficulties.\n",
    "\n",
    "\n",
    "- NAME_INCOME_TYPE: We have inferred that, Clients who are either at Maternity leave OR Unemployed has high rate of repaying their loans.\n",
    "\n",
    "\n",
    "- DAYS_BIRTH: Young and Adult people tend to have high difficulties in repaying the loan.\n",
    "\n",
    "\n",
    "- NAME_EDUCATION_TYPE: Lower Secondary and  Secondary education categories have the high probabilities of default.\n",
    "\n",
    "\n",
    "- DAYS_EMPLOYED: Clients with less employment rate is having high payment difficulties. \n",
    "\n",
    "\n",
    "- NAME_FAMILY_STATUS : civil marriage or single categories default a lot. So, we their applications can be rejected.\n",
    "\n",
    "\n",
    "- CODE_GENDER: The percentage of loan default is more for Men in Gender category.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence we recommend the bank to look into the above metrices before approving the loans to their clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = blue> Thank You !! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
